\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=0.7in]{geometry}
\usepackage[document]{ragged2e}
\usepackage{multicol}
\usepackage{listings}

\begin{document}

    \begin{center}
    \end{center}
    
    \addvspace{20mm}
        
    \begin{center}
        \huge Novel use of a Functional HDL to Simplify Development of an RNG Brute-Force Algorithm
    \end{center}
    
    \begin{center}
    \end{center}
       
    \begin{center}
        \large Andreas Stocker
    \end{center}
    
    \begin{center}
        \small \emph {University of Nicosia}
    \end{center}

    \addvspace{15mm}

    \begin{multicols}{2}

    \section*{Abstract}

    In this paper we go over the implementation details of an algorithm that brute forces
    the state of a random number generator (RNG). Recovering the internal state of an RNG can allow
    future outputs to be predicted, possibly compromising the security of a system.
    We do so using a hardware description language whose syntax
    resembles that of the Haskell language.
    The purpose of this paper is to assess the practicality of using this functional-style approach in
    designing calculation-heavy algorithms for FPGAs.
    First, we go over the basics of using this high-level hardware description named "Clash".
    We do this in a way that even programmers of more mainstream languages like Java should be able to follow.
    Finally, we go over the difficulties that were overcome as well as any special techniques involved in
    the implementation of the brute force algorithm.

    TODO - add results/conclusions after project is done

    \section{Introduction}

    Today's CPUs make use of the Von Neumann architecture. The Von Neumann architecture dictates the use
    of seperate CPU and memory modules. Furthermore, it dictates that a programs instructions be stored
    in memory.

    This works well for many of today's workloads. This current system has the benefits of decades of optimization
    and feature development.

    However, certain types of computations are bottlenecked by this approach. This is especially true for
    highly parallel calculations.

    GPUs address this need for parallelism but they are still limited by a design that prioritizes
    certain types of calculations.

    Sometimes programmers require a greater degree of control over hardware. Arguably the greatest degree
    of control developers can have is by developing their own ASICs. Modern CPUs and GPUs most
    other silicon chips are themselves ASICs. These ASICs are incredibly expensive to produce however,
    with prices often ranging from the millions into the billions.

    Therefore ASICs are well out of reach for most programmers to use for their personal projects, or even for
    medium sized companies.

    This is where FPGAs enter the picture. Less powerful FPGAs are cheap and widely available. FPGAs themselves
    are often used to prototype ASICs. However they can also be used to implement algorithms where precise control
    over circuitry is needed.

    FPGAs allow circuits to be dynamically programmed using lookup tables (LUTs). The more LUTs an FPGA
    has the more complex the circuits it can be configured for. These circuits can be configured for
    extreme parallelism. This is because unlike conventional CPUs, FGPAs are not limited by something like a core count,
    they simply have wires on a circuit.

    Despite having these strong advantages, one of the greatest disadvantages FPGAs suffer from is complexity of development.
    Since developers are working on a far lower level than even assembly language, the complexity
    of programming FPGAs is often far higher. Programmers familiar with high level languages
    like Java will not be able to use a lot of the knowledge they aquired and will need to learn electrical engineering
    concepts to create advanced FPGA projects.

    This is were the purpose of this paper is relevant. The paper will explore whether using the
    functional hardware description language (HDL) "Clash" can make FPGA development more accessible by providing
    the right abstractions.    
    
    \section{Clash Basics}

    The syntax of Clash is very much inspired by the purely functional Haskell programming language.
    The Clash project has two main components. The first major component is the compiler.
    The Clash compiler takes the Haskell-like syntax and compiles it down
    into one of the more popular hardware description languages (HDLs).
    These hardware description languages include VHDL, Verilog and SystemVerilog.
    The second major component of the Clash language are a set of libraries that
    are used for circuit design.

    Not only does Clash reuse the Haskell syntax, it actually reuses parts of the
    Glasgow Haskel Compiler.

    Now concerning the maturity of the Clash project, it has the benefit of having
    a number of years to evolve. At this time of writing it has been actively
    developed for over ten years. [TODO add link to clash docs]

    For developers to quickly get started with Clash, there are two main things they
    should be familiar with. First is basic knowledge of hardware description languages
    such as Verilog. Second, is a decent understanding of functional programming
    languages, especially Haskell.

    Before diving into the details of using Clash there is a major potential issue
    that presents itself right from the start. Programmers only familiar with
    conventional high level languages like Java and C++ may not be aware of this,
    but those with a decent amount of experience with HDLs like Verilog probably will.

    That feature is formal verification. Formal verification is indispensable for
    virtually any serious hardware design project. When looking back on their workflow,
    seasoned experts that use HDL often lament that they needlessly spent
    large amounts of time fighting bugs that formal verification could have dealt with in
    a far more efficient manner. [TODO add link to youtube talk by zipcpu creator]

    Clash does have a built in testing system so perhaps if the testing framework is
    powerful and expressive enough it may be able to compensate somewhat
    for the lack of support for formal verification.

    Finally, Clash does not appear to directly support timing analysis. Timing analysis
    is again something that only those with HDL experience will likely know about. It is
    however a critical aspect of FPGA and circuit design in general. Timing analysis is a
    very complex procedure that calculates how long a signal takes to propagate
    through a circuit. If a signal is not given enough time to propagate, inconsistencies
    will arise in the circuit. The main way to mitigate this is to reduce the clock speed
    of the circuit.

    Despite this lack of direct support for timing analysis in the Clash project itself,
    it is likely possible to perform timing analysis with standard HDL tools since
    Clash compiles to lower level HDLs.

    This could present some serious challenges since the compiled output will
    likely not be human-readable. This is something that will be explored in the paper.
    
    \section{The Algorithm}

    The algorithm chosen for these experiments is Mersenne Twister
    random number generation.

    The purpose of the algorithm is to provide a calculation that serves not only to benchmark
    the FPGA's performance vs the CPU, but also to provide a moderately complex
    scenario to measure the intricacy of the CPU and FPGA implementations.

    The most significant source code comparison will take place between the Verilog and
    Clash FPGA implementations. The CPU implentation in C is mostly there to provide
    a baseline that people with experience in conventional programming languages
    can relate to.

    The implementation algorithm was specifically chosen with the strengths of the FPGA
    in mind. Namely, the FPGA excels at doing massively parallel computations.
    Therefore this experiment does not accurately represent how the CPU compares
    with the FPGA in general. In much of general purpose computing, pieces of code
    are highly dependant on one another and need to be run in a sequence.

    This is a weakness of benchmarks in general. They obfuscate the real world performance
    of algorithms by testing very specific problems which are usually much simpler
    than sophisticated real-world programs. It is possible to benchmark real-world
    projects but these results are less likely to carry over to other projects since
    they encapsulate an amalgamation of a diverse number of operations.

    \section{C Reference Implementation}

    \lstset{language=C}

    \begin{lstlisting}
#include <stdio.h>

long holdrand;

void legacy_srand(unsigned int seed) {
  holdrand = (long)seed;
}

int legacy_rand(void) {
  return (((holdrand =
    holdrand * 214013L +
    2531011L) >> 16) & 0x7fff);
}
    \end{lstlisting}

    The builtin rand() and srand() function of the C
    standard library actually uses Mersenne Twister under the
    hood:

    \begin{lstlisting}
void __cdecl srand (unsigned int seed)
{
    #ifdef _MT
        ...
}
    \end{lstlisting}

    The Mersenne Twister algorithm is far more complex
    than the legacy C rand implementation. Therefore the older
    C implementation was used as a reference for the FPGA
    implementations so the FPGA implentations can focus
    mostly on the overall basic setup instead of
    highly involved calculations.

    The downside of chosing this legacy rand algorithm is that
    this research is less relevant to modern systems.

    For this C implementation, there are several important things
    that should be noted.

    Since the project aims to guess the random seed it is important
    to be aware of the search space.

    The holdrand variable is a long data type. This means that in theory
    this creates a search space of 2 to the power of 32 which is around four billion.

    The larger the search space, the more secure the algorithm is.
    Four billion is already not a very large number to brute force.

    However the security gets a lot worse upon closer inspection.

    The seed function takes an unsigned int. The size of the unsigned in datatype
    in C is only 2 to the power of 16. This allows for only 65 thousand values.

    This small search space not only makes it faster to search all possible seeds,
    it also allows for a longer sequence of random numbers to be examined.

    This is important because in a real-world scenario attackers usually cannot
    reseed random number generators on demand.

    This means that, depending on how much traffic a target application gets,
    thousands or even hundreds of thousands of values needs to be searched for
    every possible random seed.

    So just from the C reference implementation it becomes evident what sort
    of constraints this algorithm is working under.

    Scanning individual seeds is an algorithm that is well suited to the FPGA
    because these are completely independant parallel operations.

    Searching a seed very deeply however may present some challenges for the
    FPGA since these computations that depend on one another, creating a
    need for intermediate storage.

    It will likely be best to keep storage within logic cells instead of memory.

    Logic cells have far less total memory that the dedicated memory unit of an FPGA,
    but they can be accessed in parallel unlike the dedicated memory which costs
    clock cycles for every access.
    
    \section{Related Work}

    Todo - add this

    THIS COMES NEAR THE END

    
    \end{multicols}

    \break
    \section*{References}

    \begin{enumerate}

    \item Chandrasekaran, Shrutisagar, and Abbes Amira. "High performance FPGA implementation of the Mersenne Twister." 4th IEEE International Symposium on Electronic Design, Test and Applications (delta 2008). IEEE, 2008.

    \end{enumerate}
    
\end{document}
